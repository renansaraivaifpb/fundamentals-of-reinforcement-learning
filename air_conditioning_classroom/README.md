# Sistema de Controle de Ar-Condicionado com Aprendizagem por ReforÃ§o

Este projeto implementa um sistema inteligente de controle de ar-condicionado para salas de aula usando **Aprendizagem por ReforÃ§o (RL)**. O objetivo Ã© desenvolver um agente que aprenda a controlar o sistema de climatizaÃ§Ã£o de forma a balancear o **conforto tÃ©rmico** dos usuÃ¡rios e a **eficiÃªncia energÃ©tica**.

## ğŸ¯ Objetivos

- **Conforto TÃ©rmico**: Manter a temperatura da sala dentro da faixa de conforto (22-26Â°C)
- **EficiÃªncia EnergÃ©tica**: Minimizar o consumo energÃ©tico do ar-condicionado
- **Adaptabilidade**: Aprender polÃ­ticas que se adaptem a diferentes cenÃ¡rios (ocupaÃ§Ã£o, horÃ¡rio, temperatura externa)

## ğŸ—ï¸ Arquitetura do Sistema

### Ambiente de SimulaÃ§Ã£o (`classroom_ac_env.py`)
- **Estados**: Temperatura, ocupaÃ§Ã£o, hora do dia, estado do AC
- **AÃ§Ãµes**: OFF, LOW, MEDIUM, HIGH (4 nÃ­veis de potÃªncia)
- **Recompensas**: Balanceamento entre conforto tÃ©rmico e consumo energÃ©tico
- **DinÃ¢mica**: Modelo tÃ©rmico simplificado com transferÃªncia de calor

### Agente Q-Learning (`ac_qlearning_agent.py`)
- **Algoritmo**: Q-Learning com polÃ­tica Îµ-greedy
- **ExploraÃ§Ã£o**: Decaimento adaptativo da taxa de exploraÃ§Ã£o
- **AvaliaÃ§Ã£o**: MÃ©tricas de performance e anÃ¡lise de polÃ­ticas

### Sistema de AnÃ¡lise (`analysis_utils.py`)
- **VisualizaÃ§Ãµes**: Heatmaps, grÃ¡ficos de temperatura, anÃ¡lise de eficiÃªncia
- **RelatÃ³rios**: AnÃ¡lise detalhada da polÃ­tica aprendida
- **Dashboard**: Interface completa de anÃ¡lise de resultados

## ğŸ“Š CaracterÃ­sticas TÃ©cnicas

### Modelagem do Ambiente
- **Sala de Aula**: 8m Ã— 6m Ã— 3m (144 mÂ³)
- **Capacidade**: AtÃ© 30 ocupantes
- **Temperatura de Conforto**: 22-26Â°C
- **Estados Discretos**: 2,520 estados (21 temp Ã— 6 ocupaÃ§Ã£o Ã— 20 hora)
- **AÃ§Ãµes**: 4 nÃ­veis de potÃªncia do ar-condicionado

### FunÃ§Ã£o de Recompensa
```python
# Recompensa por conforto tÃ©rmico
comfort_rewards = {
    'VERY_COLD': -2.0,
    'COLD': -1.0,
    'COMFORTABLE': 1.0,
    'WARM': -1.0,
    'VERY_HOT': -2.0
}

# Penalidade por consumo energÃ©tico
energy_penalty = -consumption * 0.1

# Recompensa total
total_reward = comfort_reward + energy_penalty
```

### ParÃ¢metros de Treinamento
- **Taxa de Aprendizado (Î±)**: 0.1
- **Fator de Desconto (Î³)**: 0.95
- **Taxa de ExploraÃ§Ã£o (Îµ)**: 0.2 â†’ 0.01 (decaimento)
- **EpisÃ³dios**: 1,000
- **DuraÃ§Ã£o do EpisÃ³dio**: 24 horas (240 passos de tempo)

## ğŸš€ Como Usar

### InstalaÃ§Ã£o
```bash
# Instalar dependÃªncias
pip install numpy matplotlib seaborn pandas

# Clonar repositÃ³rio
git clone <repository-url>
cd air_conditioning_classroom
```

### Treinamento BÃ¡sico
```python
from classroom_ac_env import ClassroomACEnvironment, ClassroomConfig
from ac_qlearning_agent import ACQLearningAgent, QLearningConfig

# Cria ambiente e agente
env = ClassroomACEnvironment(ClassroomConfig())
agent = ACQLearningAgent(env.n_states, env.n_actions, QLearningConfig())

# Treina o agente
history = agent.train(env, verbose=True)

# Avalia a polÃ­tica
eval_stats = agent.evaluate(env, episodes=10)
```

### ExecuÃ§Ã£o Completa
```bash
# Executa experimentos comparativos
python main_train.py

# Cria dashboard de anÃ¡lise
python analysis_utils.py
```

## ğŸ“ˆ Resultados Esperados

### MÃ©tricas de Performance
- **Conforto TÃ©rmico**: >80% do tempo na faixa de conforto
- **EficiÃªncia EnergÃ©tica**: Consumo otimizado baseado na demanda
- **ConvergÃªncia**: EstabilizaÃ§Ã£o da polÃ­tica apÃ³s ~500 episÃ³dios

### Comportamentos Aprendidos
- **Temperatura Baixa + OcupaÃ§Ã£o Alta**: AC em potÃªncia mÃ©dia/alta
- **Temperatura Alta + OcupaÃ§Ã£o Baixa**: AC em potÃªncia baixa
- **HorÃ¡rio Noturno**: ReduÃ§Ã£o do uso do AC
- **Temperatura ConfortÃ¡vel**: AC desligado ou baixa potÃªncia

## ğŸ”¬ Experimentos DisponÃ­veis

### 1. Baseline
- ConfiguraÃ§Ã£o padrÃ£o para comparaÃ§Ã£o
- Î±=0.1, Î³=0.95, Îµ=0.2

### 2. High Exploration
- Maior exploraÃ§Ã£o inicial
- Îµ=0.5, decaimento mais lento

### 3. Low Learning Rate
- Taxa de aprendizado reduzida
- Î±=0.05 para aprendizado mais suave

### 4. High Discount Factor
- Maior consideraÃ§Ã£o do futuro
- Î³=0.99 para planejamento de longo prazo

## ğŸ“Š AnÃ¡lises DisponÃ­veis

### 1. Heatmap da Q-Table
- VisualizaÃ§Ã£o dos valores Q aprendidos
- IdentificaÃ§Ã£o de padrÃµes na polÃ­tica

### 2. AnÃ¡lise de Temperatura vs Conforto
- RelaÃ§Ã£o entre temperatura e nÃ­vel de conforto
- Efetividade do controle tÃ©rmico

### 3. AnÃ¡lise de EficiÃªncia EnergÃ©tica
- Conforto vs Consumo energÃ©tico
- OtimizaÃ§Ã£o da razÃ£o eficiÃªncia

### 4. RelatÃ³rio da PolÃ­tica
- AnÃ¡lise detalhada das regras aprendidas
- RecomendaÃ§Ãµes baseadas no comportamento

## ğŸ›ï¸ ConfiguraÃ§Ãµes AvanÃ§adas

### PersonalizaÃ§Ã£o do Ambiente
```python
config = ClassroomConfig(
    length=10.0,           # Comprimento da sala (m)
    width=8.0,             # Largura da sala (m)
    height=3.0,            # Altura da sala (m)
    max_occupancy=40,      # Capacidade mÃ¡xima
    temp_comfort_min=21.0, # Temperatura mÃ­nima confortÃ¡vel
    temp_comfort_max=25.0  # Temperatura mÃ¡xima confortÃ¡vel
)
```

### PersonalizaÃ§Ã£o do Agente
```python
agent_config = QLearningConfig(
    alpha=0.15,            # Taxa de aprendizado
    gamma=0.98,            # Fator de desconto
    epsilon=0.3,           # Taxa de exploraÃ§Ã£o inicial
    epsilon_min=0.005,     # Taxa de exploraÃ§Ã£o mÃ­nima
    episodes=2000          # NÃºmero de episÃ³dios
)
```

## ğŸ“ Estrutura do Projeto

```
air_conditioning_classroom/
â”œâ”€â”€ classroom_ac_env.py      # Ambiente de simulaÃ§Ã£o
â”œâ”€â”€ ac_qlearning_agent.py    # Agente Q-Learning
â”œâ”€â”€ main_train.py           # Script principal de treinamento
â”œâ”€â”€ analysis_utils.py       # UtilitÃ¡rios de anÃ¡lise
â”œâ”€â”€ README.md               # Este arquivo
â””â”€â”€ results_YYYYMMDD_HHMMSS/ # Resultados dos experimentos
    â”œâ”€â”€ experiment_comparison.png
    â”œâ”€â”€ policy_behavior_analysis.png
    â”œâ”€â”€ baseline_model.pkl
    â””â”€â”€ baseline_results.json
```

## ğŸ”§ DependÃªncias

- **Python**: 3.7+
- **NumPy**: ComputaÃ§Ã£o numÃ©rica
- **Matplotlib**: VisualizaÃ§Ãµes
- **Seaborn**: GrÃ¡ficos estatÃ­sticos
- **Pandas**: ManipulaÃ§Ã£o de dados

## ğŸ“š ReferÃªncias

1. **Sutton, R. S., & Barto, A. G.** (2018). *Reinforcement Learning: An Introduction*. MIT Press.
2. **Watkins, C. J. C. H.** (1989). Learning from delayed rewards. *PhD thesis, University of Cambridge*.
3. **Mnih, V., et al.** (2015). Human-level control through deep reinforcement learning. *Nature*.

## ğŸ¤ ContribuiÃ§Ãµes

ContribuiÃ§Ãµes sÃ£o bem-vindas! Ãreas de interesse:
- Melhorias no modelo tÃ©rmico
- Novos algoritmos de RL
- OtimizaÃ§Ãµes de performance
- Novas mÃ©tricas de avaliaÃ§Ã£o

## ğŸ“„ LicenÃ§a

Este projeto estÃ¡ sob a licenÃ§a MIT. Veja o arquivo `LICENSE` para detalhes.

## ğŸ‘¨â€ğŸ’» Autor

**Renan** - Desenvolvido com assistÃªncia de IA para fins educacionais em Aprendizagem por ReforÃ§o.

---

*Este projeto demonstra a aplicaÃ§Ã£o prÃ¡tica de algoritmos de RL em problemas de controle de sistemas fÃ­sicos, especificamente no domÃ­nio de eficiÃªncia energÃ©tica e conforto tÃ©rmico.*